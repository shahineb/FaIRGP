{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5fb82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext line_profiler\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419e7393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (typeof IPython !== 'undefined') { IPython.OutputArea.prototype._should_scroll = function(lines){ return false; }}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import numexpr as ne\n",
    "import pandas as pd\n",
    "import torch\n",
    "import gpytorch\n",
    "from gpytorch import means, kernels, likelihoods, distributions, lazy\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import xarray as xr\n",
    "import tqdm\n",
    "import utils as utils\n",
    "\n",
    "\n",
    "base_dir = os.path.join(os.getcwd(), '..')\n",
    "sys.path.append(base_dir)\n",
    "\n",
    "from src.fair import run, get_params\n",
    "from src.fair.ancil import get_gas_params, get_thermal_params\n",
    "from src.preprocessing import load_emissions_dataset, load_response_dataset\n",
    "from src.structures import Scenario, ScenarioDataset\n",
    "import utils_spatial as spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26709e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_keys = ['historical', 'ssp126', 'ssp370', 'ssp585']\n",
    "test_keys = ['ssp245']\n",
    "keys = train_keys + test_keys\n",
    "inputs = {key: load_emissions_dataset(f'../data/inputs_{key}.nc') for key in keys}\n",
    "outputs = {key: load_response_dataset(f'../data/outputs_{key}.nc') for key in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7fb065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make non-spatial scenarios\n",
    "def make_scenario(name, hist_scenario=None):\n",
    "    time, _, emission, tas = utils.extract_arrays(inputs[name], outputs[name])\n",
    "    scenario = Scenario(name=name,\n",
    "                        timesteps=torch.from_numpy(time).float(),\n",
    "                        emissions=torch.from_numpy(emission).float().T,\n",
    "                        tas=torch.from_numpy(tas).float(),\n",
    "                        hist_scenario=hist_scenario)\n",
    "    return scenario\n",
    "\n",
    "hist_scenario = make_scenario('historical')\n",
    "ssps = ['ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "scenarios = {'historical': hist_scenario}\n",
    "for name in ssps:\n",
    "    scenario = make_scenario(name, hist_scenario)\n",
    "    scenarios[name] = scenario\n",
    "    \n",
    "train_scenarios = ScenarioDataset(scenarios=list([scenarios[key] for key in train_keys]),\n",
    "                                  hist_scenario=hist_scenario)\n",
    "test_scenarios = ScenarioDataset(scenarios=list([scenarios[key] for key in test_keys]),\n",
    "                                 hist_scenario=hist_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b328b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute global FaIR forcing time serie Fdet\n",
    "def compute_forcings(scenario_dataset):\n",
    "    base_kwargs = get_params()\n",
    "    forcings = dict()\n",
    "    for name, scenario in scenario_dataset.scenarios.items():\n",
    "        res = run(scenario.full_timesteps.numpy(),\n",
    "                  scenario.full_emissions.T.numpy(),\n",
    "                  base_kwargs)\n",
    "        Fdet = np.sum(res['RF'].T, axis=-1)\n",
    "        Fdet = scenario.trim_hist(Fdet)\n",
    "        forcings.update({scenario: torch.from_numpy(Fdet).float()})\n",
    "    return forcings\n",
    "\n",
    "train_Fdet = compute_forcings(train_scenarios)\n",
    "test_Fdet = compute_forcings(test_scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b825dab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy grids of dj and qj\n",
    "base_kwargs = get_params()\n",
    "\n",
    "d = base_kwargs['d']\n",
    "q = base_kwargs['q']\n",
    "\n",
    "d_map = np.tile(d, 96 * 144).reshape(96, 144, 3)\n",
    "q_map = np.tile(q, 96 * 144).reshape(96, 144, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfc099aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute spatialised mean thermal responses based on Fdet\n",
    "def step_temperature(S_old, F, q, d, dt=1):\n",
    "    decay_factor = ne.evaluate(\"exp(-dt/d)\")  # noqa: F841\n",
    "    S_new = ne.evaluate(\"q * F * (1 - decay_factor) + S_old * decay_factor\")\n",
    "    T = ne.evaluate(\"sum( (S_old + S_new)/2, axis=0 )\")\n",
    "    return S_new, T\n",
    "\n",
    "def compute_spatial_mjs(Fdet, d_map, q_map, timesteps):\n",
    "    n_timesteps = len(timesteps)\n",
    "    S = np.zeros((n_timesteps,) + d_map.shape)\n",
    "    dt = timesteps[0]\n",
    "    for i, tstep in enumerate(timesteps):\n",
    "        dt = max(1, tstep - dt)\n",
    "        S[i], _ = step_temperature(S[max(i - 1, 0)], Fdet[i], q_map, d_map, dt)\n",
    "        dt = tstep\n",
    "    return S\n",
    "\n",
    "Fdet = train_Fdet[train_scenarios[0]]\n",
    "mjs = compute_spatial_mjs(Fdet, d_map, q_map, train_scenarios[0].timesteps) # time*lat*lon*nbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5029ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make spatial scenarios\n",
    "spatial_hist_scenario = spatial.make_scenario(inputs, outputs, 'historical')\n",
    "ssps = ['ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "spatial_scenarios = {'historical': spatial_hist_scenario}\n",
    "for name in ssps:\n",
    "    scenario = spatial.make_scenario(inputs, outputs, name, spatial_hist_scenario)\n",
    "    spatial_scenarios[name] = scenario\n",
    "    \n",
    "spatial_train_scenarios = ScenarioDataset(scenarios=list([spatial_scenarios[key] for key in train_keys]),\n",
    "                                          hist_scenario=spatial_hist_scenario)\n",
    "spatial_test_scenarios = ScenarioDataset(scenarios=list([spatial_scenarios[key] for key in test_keys]),\n",
    "                                         hist_scenario=spatial_hist_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ef2278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute forcing kernel on spatial emission maps\n",
    "rff = kernels.RFFKernel(num_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2630374",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = spatial_train_scenarios.mu_emissions\n",
    "sigma = spatial_train_scenarios.sigma_emissions\n",
    "scenario_emissions_std = (spatial_train_scenarios[0].full_emissions - mu) / sigma\n",
    "dataset_emissions_std = (spatial_train_scenarios.full_emissions - mu) / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb5bb1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = dataset_emissions_std.reshape(-1, 4)\n",
    "bar = scenario_emissions_std.reshape(-1, 4)\n",
    "# K = rff(foo, bar).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925a7158",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_dataset = ?\n",
    "kernel = ?\n",
    "\n",
    "mu, sigma = scenario_dataset.mu_inputs, scenario_dataset.sigma_inputs\n",
    "dataset_emissions_std = (scenario_dataset.full_emissions - mu) / sigma\n",
    "flat_dataset_emissions_std = dataset_emissions_std.reshape(-1, dataset_emissions_std.size(-1))\n",
    "flat_dataset_size = flat_dataset_emissions_std.size(0)\n",
    "\n",
    "\n",
    "for scenario in scenario_dataset.scenarios.values():\n",
    "    scenario_emissions_std = (scenario.full_emissions - mu) / sigma\n",
    "    flat_scenario_emissions_std = scenario_emissions_std.size(-1, scenario_emissions_std.size(-1))\n",
    "    flat_scenario_size = flat_scenario_emissions_std.size(0)\n",
    "\n",
    "    I_old = torch.zeros((flat_dataset_size, flat_scenario_size, len(d)))\n",
    "    Kj = ?\n",
    "\n",
    "    for t in range(1, len(scenario_emission_std)):\n",
    "        flat_scenario_emissions_std_t = flat_scenario_emissions_std[t]\n",
    "        K_new = kernel(flat_dataset_emissions_std, flat_scenario_emissions_std_t)\n",
    "        I_new = step_I(I_old, K_new, d?)\n",
    "        I_old = I_new.squeeze()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6dd3120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([918, 96, 144, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_I(scenario_dataset, kernel, d):\n",
    "    I = [compute_I_scenario(scenario_dataset, scenario, kernel, d)\n",
    "         for scenario in scenario_dataset.scenarios.values()]\n",
    "    I = torch.cat(I, dim=-2)\n",
    "    return I\n",
    "\n",
    "\n",
    "def compute_I_scenario(scenario_dataset, scenario, kernel, d):\n",
    "    mu, sigma = scenario_dataset.mu_inputs, scenario_dataset.sigma_inputs\n",
    "    scenario_emissions_std = (scenario.full_inputs - mu) / sigma\n",
    "    dataset_emissions_std = (scenario_dataset.full_inputs - mu) / sigma\n",
    "\n",
    "    K = kernel(dataset_emissions_std, scenario_emissions_std).evaluate().unsqueeze(-1)\n",
    "    I = torch.zeros((K.size(0), K.size(1), len(d)))\n",
    "    for t in range(1, len(scenario_emissions_std)):\n",
    "        I_old = I[:, t - 1]\n",
    "        K_new = K[:, t]\n",
    "        I_new = step_I(I_old, K_new, d.unsqueeze(0))\n",
    "        I[:, t] = I_new.squeeze()\n",
    "    return I\n",
    "\n",
    "\n",
    "def compute_covariance(scenario_dataset, I, q, d):\n",
    "    Kj = [compute_covariance_scenario(scenario_dataset, scenario, I, q, d)\n",
    "          for scenario in scenario_dataset.scenarios.values()]\n",
    "    Kj = torch.cat(Kj, dim=-2)\n",
    "    Kj = scenario_dataset.trim_hist(Kj)\n",
    "    return Kj\n",
    "\n",
    "\n",
    "def compute_covariance_scenario(scenario_dataset, scenario, I, q, d):\n",
    "    I_scenario = I[scenario_dataset.full_slices[scenario.name]]\n",
    "    Kj = torch.zeros_like(I_scenario)\n",
    "    for t in range(1, I_scenario.size(0)):\n",
    "        Kj_old = Kj[t - 1]\n",
    "        I_new = I_scenario[t]\n",
    "        Kj_new = step_kernel(Kj_old, I_new, q.unsqueeze(0), d.unsqueeze(0))\n",
    "        Kj[t] = Kj_new\n",
    "    Kj = scenario.trim_hist(Kj)\n",
    "    return Kj.permute(1, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f2229bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([165, 96, 144, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenario_emissions_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3d1c1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12690432, 4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4f45e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2280960, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411b17c3",
   "metadata": {},
   "source": [
    "What do I need to do to run a simple experiment:\n",
    "- Take the usual GP model\n",
    "- ~Can I use ScenarioDataset? PRobably not, that's where I need to start... because this is going to be useful either way~\n",
    "- Allow d and q to be functions\n",
    "- Ugh, is it going to be compatible with all the subfunctions? Probably not, gonna have to be careful with that\n",
    "- ~Can evaluate d, q than flatten into 3 * n_pixel boxes and then reshape. Good trick to avoid coding too much in case it fails (or even as a first attempt)~ -> cannot use the code as is because it won't scale... maybe only some latitudes/longitudes at first"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "sandbox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
