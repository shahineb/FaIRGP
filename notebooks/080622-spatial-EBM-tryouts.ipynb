{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5fb82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext line_profiler\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419e7393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (typeof IPython !== 'undefined') { IPython.OutputArea.prototype._should_scroll = function(lines){ return false; }}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import gpytorch\n",
    "from gpytorch import means, kernels, likelihoods, distributions, lazy\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import xarray as xr\n",
    "import tqdm\n",
    "import utils as utils\n",
    "\n",
    "\n",
    "base_dir = os.path.join(os.getcwd(), '..')\n",
    "sys.path.append(base_dir)\n",
    "\n",
    "from src.fair import run, get_params\n",
    "from src.fair.ancil import get_gas_params, get_thermal_params\n",
    "from src.preprocessing import load_emissions_dataset, load_response_dataset\n",
    "from src.structures import Scenario, ScenarioDataset\n",
    "import utils_spatial as spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26709e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_keys = ['historical', 'ssp126', 'ssp370', 'ssp585']\n",
    "test_keys = ['ssp245']\n",
    "keys = train_keys + test_keys\n",
    "inputs = {key: load_emissions_dataset(f'../data/inputs_{key}.nc') for key in keys}\n",
    "outputs = {key: load_response_dataset(f'../data/outputs_{key}.nc') for key in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7fb065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scenario(name, hist_scenario=None):\n",
    "    time, _, emission, tas = utils.extract_arrays(inputs[name], outputs[name])\n",
    "    scenario = Scenario(name=name,\n",
    "                        timesteps=torch.from_numpy(time).float(),\n",
    "                        emissions=torch.from_numpy(emission).float().T,\n",
    "                        tas=torch.from_numpy(tas).float(),\n",
    "                        hist_scenario=hist_scenario)\n",
    "    return scenario\n",
    "\n",
    "hist_scenario = make_scenario('historical')\n",
    "ssps = ['ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "scenarios = {'historical': hist_scenario}\n",
    "for name in ssps:\n",
    "    scenario = make_scenario(name, hist_scenario)\n",
    "    scenarios[name] = scenario\n",
    "    \n",
    "train_scenarios = ScenarioDataset(scenarios=list([scenarios[key] for key in train_keys]),\n",
    "                                  hist_scenario=hist_scenario)\n",
    "test_scenarios = ScenarioDataset(scenarios=list([scenarios[key] for key in test_keys]),\n",
    "                                 hist_scenario=hist_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa72c89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_hist_scenario = spatial.make_scenario(inputs, outputs, 'historical')\n",
    "ssps = ['ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "spatial_scenarios = {'historical': spatial_hist_scenario}\n",
    "for name in ssps:\n",
    "    scenario = spatial.make_scenario(inputs, outputs, name, spatial_hist_scenario)\n",
    "    spatial_scenarios[name] = scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1196de1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_train_scenarios = ScenarioDataset(scenarios=list([spatial_scenarios[key] for key in train_keys]),\n",
    "                                          hist_scenario=spatial_hist_scenario)\n",
    "spatial_test_scenarios = ScenarioDataset(scenarios=list([spatial_scenarios[key] for key in test_keys]),\n",
    "                                         hist_scenario=spatial_hist_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c9959ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_kwargs = get_params()\n",
    "\n",
    "d = base_kwargs['d']\n",
    "q = base_kwargs['q']\n",
    "\n",
    "d_map = np.tile(d, 10 * 10).reshape(10 * 10, 3)\n",
    "q_map = np.tile(q, 10 * 10).reshape(10 * 10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e929fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_simple = spatial.compute_means(test_scenarios, d.reshape(1, 3), q.reshape(1, 3))\n",
    "means_multiple = spatial.compute_means(test_scenarios, d_map, q_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f66f7ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = means_multiple[test_scenarios[0]].reshape(10, 10, 86, 3).permute(2, 0, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "438a8fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0007, 0.0023, 0.0043, 0.0064, 0.0088, 0.0117, 0.0149, 0.0182, 0.0217,\n",
       "        0.0252, 0.0287, 0.0322, 0.0358, 0.0394, 0.0431, 0.0468, 0.0506, 0.0545,\n",
       "        0.0584, 0.0624, 0.0665, 0.0705, 0.0746, 0.0779, 0.0799, 0.0811, 0.0819,\n",
       "        0.0824, 0.0828, 0.0831, 0.0834, 0.0836, 0.0837, 0.0839, 0.0841, 0.0843,\n",
       "        0.0844, 0.0846, 0.0848, 0.0849, 0.0851, 0.0853, 0.0854, 0.0856, 0.0857,\n",
       "        0.0859, 0.0861, 0.0862, 0.0864, 0.0865, 0.0867, 0.0868, 0.0870, 0.0871,\n",
       "        0.0873, 0.0874, 0.0876, 0.0877, 0.0879, 0.0880, 0.0882, 0.0883, 0.0885,\n",
       "        0.0886, 0.0888, 0.0889, 0.0891, 0.0892, 0.0893, 0.0895, 0.0896, 0.0898,\n",
       "        0.0899, 0.0901, 0.0902, 0.0903, 0.0905, 0.0906, 0.0907, 0.0909, 0.0910,\n",
       "        0.0912, 0.0913, 0.0914, 0.0916, 0.0917, 0.0918, 0.0920, 0.0921, 0.0922,\n",
       "        0.0923, 0.0925, 0.0926, 0.0927, 0.0929, 0.0930, 0.0931, 0.0932, 0.0934,\n",
       "        0.0935, 0.0936, 0.0937, 0.0939, 0.0940, 0.0941, 0.0942, 0.0944, 0.0945,\n",
       "        0.0946, 0.0947, 0.0948, 0.0950, 0.0951, 0.0952, 0.0953, 0.0954, 0.0955,\n",
       "        0.0957, 0.0958, 0.0959, 0.0960, 0.0961, 0.0962, 0.0963, 0.0965, 0.0966,\n",
       "        0.0967, 0.0968, 0.0969, 0.0970, 0.0971, 0.0972, 0.0973, 0.0974, 0.0975,\n",
       "        0.0977, 0.0978, 0.0979, 0.0980, 0.0981, 0.0982, 0.0983, 0.0984, 0.0985,\n",
       "        0.0986, 0.0987, 0.0988, 0.0989, 0.0990, 0.0991, 0.0992, 0.0993, 0.0994,\n",
       "        0.0995, 0.0996, 0.0997, 0.0998, 0.0999, 0.1000, 0.1001, 0.1002, 0.1003,\n",
       "        0.1004, 0.1005, 0.1006])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo[:, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fec4e3e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 144, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_map.reshape(96, 144, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8efb7f72",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2280960.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6842880 / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41a95c62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6842880"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "165 * 96 * 144 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67a0a141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hist_scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411b17c3",
   "metadata": {},
   "source": [
    "What do I need to do to run a simple experiment:\n",
    "- Take the usual GP model\n",
    "- ~Can I use ScenarioDataset? PRobably not, that's where I need to start... because this is going to be useful either way~\n",
    "- Allow d and q to be functions\n",
    "- Ugh, is it going to be compatible with all the subfunctions? Probably not, gonna have to be careful with that\n",
    "- ~Can evaluate d, q than flatten into 3 * n_pixel boxes and then reshape. Good trick to avoid coding too much in case it fails (or even as a first attempt)~ -> cannot use the code as is because it won't scale... maybe only some latitudes/longitudes at first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1311e839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "sandbox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
